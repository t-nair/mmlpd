# Gen AI Hub
## Full Project Database
* [Jump to tables by topic](#tables-by-topic)

| Topic                                     | Project Idea                                                              | Difficulty    |
|-------------------------------------------|---------------------------------------------------------------------------|---------------|
| Generative Adversarial Networks (GANs)      | Train a GAN to generate synthetic digit images.                           | Beginner      |
| Generative Adversarial Networks (GANs)      | Generate new face images using a pre-trained GAN.                        | Beginner      |
| Generative Adversarial Networks (GANs)      | Develop a conditional GAN for class-specific image generation.            | Intermediate  |
| Generative Adversarial Networks (GANs)      | Use CycleGAN to translate photos into a different style.                 | Intermediate  |
| Generative Adversarial Networks (GANs)      | Apply GANs to create data augmentations for small datasets.              | Intermediate  |
| Generative Adversarial Networks (GANs)      | Build a StyleGAN-style model for high-res image generation.               | Advanced      |
| Generative Adversarial Networks (GANs)      | Train a BigGAN for diverse realistic image synthesis.                    | Advanced      |
| Generative Adversarial Networks (GANs)      | Use GAN for image super-resolution.                                     | Advanced      |
| Generative Adversarial Networks (GANs)      | Create a text-to-image GAN (e.g. using AttnGAN).                        | Advanced      |
| Generative Adversarial Networks (GANs)      | Explore GAN-based anomaly detection in images.                           | Advanced      |
| Variational Autoencoders (VAEs)           | Use a VAE to generate variations of simple shapes.                       | Beginner      |
| Variational Autoencoders (VAEs)           | Denoise images using a basic VAE.                                        | Beginner      |
| Variational Autoencoders (VAEs)           | Train a VAE on handwriting samples to generate digits.                    | Intermediate  |
| Variational Autoencoders (VAEs)           | Use a convolutional VAE for face image generation.                       | Intermediate  |
| Variational Autoencoders (VAEs)           | Explore latent space arithmetic with a trained VAE.                       | Intermediate  |
| Variational Autoencoders (VAEs)           | Use VAE for 3D object generation from point clouds.                       | Advanced      |
| Variational Autoencoders (VAEs)           | Combine VAE with GAN (VAE-GAN) for sharper images.                       | Advanced      |
| Variational Autoencoders (VAEs)           | Apply VAE to generate new drug-like molecular graphs.                    | Advanced      |
| Variational Autoencoders (VAEs)           | Investigate Î²-VAE for disentangled representation learning.              | Advanced      |
| Variational Autoencoders (VAEs)           | Develop a hierarchical VAE for long-sequence generation.                 | Advanced      |
| Diffusion Models                          | Use a diffusion model to generate simple 1D noise patterns.              | Beginner      |
| Diffusion Models                          | Train a toy diffusion model to reconstruct noisy images.                 | Beginner      |
| Diffusion Models                          | Implement denoising diffusion on MNIST digit images.                     | Intermediate  |
| Diffusion Models                          | Use a pretrained diffusion model (Stable Diffusion) to generate art.      | Intermediate  |
| Diffusion Models                          | Apply diffusion model for image super-resolution.                        | Intermediate  |
| Diffusion Models                          | Build a text-to-image diffusion pipeline (with CLIP guidance).            | Advanced      |
| Diffusion Models                          | Research improving sampling speed of diffusion models.                   | Advanced      |
| Diffusion Models                          | Use diffusion for 3D shape or point-cloud generation.                    | Advanced      |
| Diffusion Models                          | Combine diffusion with GAN (DiffusionGAN) for efficiency.                | Advanced      |
| Diffusion Models                          | Explore conditional diffusion for class-guided generation.               | Advanced      |
| Autoregressive Models (GPT, RNN-based)    | Train an RNN language model to predict the next word.                   | Beginner      |
| Autoregressive Models (GPT, RNN-based)    | Use GPT-2 to generate a short story given a prompt.                     | Beginner      |
| Autoregressive Models (GPT, RNN-based)    | Implement a character-level RNN text generator.                         | Intermediate  |
| Autoregressive Models (GPT, RNN-based)    | Fine-tune an autoregressive model for code generation.                  | Intermediate  |
| Autoregressive Models (GPT, RNN-based)    | Explore sampling methods (top-k, nucleus) with GPT.                     | Intermediate  |
| Autoregressive Models (GPT, RNN-based)    | Train a Transformer-XL on long-text sequences.                          | Advanced      |
| Autoregressive Models (GPT, RNN-based)    | Build a conditional text generator (e.g. style transfer).               | Advanced      |
| Autoregressive Models (GPT, RNN-based)    | Research sparse autoregressive architectures (SparseGPT).               | Advanced      |
| Autoregressive Models (GPT, RNN-based)    | Implement an RL loop to refine generated text quality.                  | Advanced      |
| Autoregressive Models (GPT, RNN-based)    | Apply autoregressive model to music (MIDI) generation.                  | Advanced      |
| Normalizing Flow Models                   | Implement a simple RealNVP for 2D toy data.                              | Beginner      |
| Normalizing Flow Models                   | Use a normalizing flow to model a simple Gaussian mixture.              | Beginner      |
| Normalizing Flow Models                   | Train MAF (Masked Autoregressive Flow) on image data.                   | Intermediate  |
| Normalizing Flow Models                   | Use flows for density estimation of sensor data.                        | Intermediate  |
| Normalizing Flow Models                   | Combine flows with VAEs for better priors.                              | Intermediate  |
| Normalizing Flow Models                   | Develop a flow-based generator for high-res images.                     | Advanced      |
| Normalizing Flow Models                   | Research invertible layers in deep generative models.                    | Advanced      |
| Normalizing Flow Models                   | Use normalizing flows for video frame prediction.                       | Advanced      |
| Normalizing Flow Models                   | Implement a continuous-time flow (ODE-based) for audio.                 | Advanced      |
| Normalizing Flow Models                   | Explore multi-scale flows for complex high-dimensional data.            | Advanced      |
| Transformers for Generation (GPT-style)   | Use GPT to write simple dialogue between two characters.                | Beginner      |
| Transformers for Generation (GPT-style)   | Generate poetry with a small transformer model.                          | Beginner      |
| Transformers for Generation (GPT-style)   | Fine-tune GPT on a specialized text corpus (e.g. legal).               | Intermediate  |
| Transformers for Generation (GPT-style)   | Build a headline generator using an encoder-decoder transformer.        | Intermediate  |
| Transformers for Generation (GPT-style)   | Experiment with GPT output diversity via temperature tuning.           | Intermediate  |
| Transformers for Generation (GPT-style)   | Develop a multi-lingual text generation model with transformer.        | Advanced      |
| Transformers for Generation (GPT-style)   | Research efficient transformers (Reformer, Longformer) for long contexts.| Advanced      |
| Transformers for Generation (GPT-style)   | Train a retrieval-augmented generator with external knowledge.         | Advanced      |
| Transformers for Generation (GPT-style)   | Implement a transformer to generate program code.                      | Advanced      |
| Transformers for Generation (GPT-style)   | Use a transformer model to generate music sequences.                   | Advanced      |
| Auto-Regressive NLP Models (RNN)          | Train a char-level LSTM to generate text from Wikipedia.              | Beginner      |
| Auto-Regressive NLP Models (RNN)          | Use an RNN to continue writing a given paragraph.                    | Beginner      |
| Auto-Regressive NLP Models (RNN)          | Build an LSTM to generate captions for images.                        | Intermediate  |
| Auto-Regressive NLP Models (RNN)          | Implement scheduled sampling to improve RNN generation.               | Intermediate  |
| Auto-Regressive NLP Models (RNN)          | Use attention in an RNN language model.                               | Intermediate  |
| Auto-Regressive NLP Models (RNN)          | Combine RNN decoder with BERT encoder for sequence generation.        | Advanced      |
| Auto-Regressive NLP Models (RNN)          | Research variational RNNs (VRNN) for diverse generation.             | Advanced      |
| Auto-Regressive NLP Models (RNN)          | Use RL to fine-tune RNN-based chatbot responses.                    | Advanced      |
| Auto-Regressive NLP Models (RNN)          | Train an RNN to generate sequential graph structures.                 | Advanced      |
| Auto-Regressive NLP Models (RNN)          | Explore meta-learning for rapid adaptation of generators.            | Advanced      |

## Tables By Topic
### Generative Adversarial Networks (GANs)
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Train a GAN to generate synthetic digit images.                   | Beginner      |
| Generate new face images using a pre-trained GAN.                | Beginner      |
| Develop a conditional GAN for class-specific image generation.    | Intermediate  |
| Use CycleGAN to translate photos into a different style.         | Intermediate  |
| Apply GANs to create data augmentations for small datasets.      | Intermediate  |
| Build a StyleGAN-style model for high-res image generation.       | Advanced      |
| Train a BigGAN for diverse realistic image synthesis.           | Advanced      |
| Use GAN for image super-resolution.                             | Advanced      |
| Create a text-to-image GAN (e.g. using AttnGAN).                  | Advanced      |
| Explore GAN-based anomaly detection in images.                   | Advanced      |

### Variational Autoencoders (VAEs)
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Use a VAE to generate variations of simple shapes.                | Beginner      |
| Denoise images using a basic VAE.                                 | Beginner      |
| Train a VAE on handwriting samples to generate digits.            | Intermediate  |
| Use a convolutional VAE for face image generation.                | Intermediate  |
| Explore latent space arithmetic with a trained VAE.                | Intermediate  |
| Use VAE for 3D object generation from point clouds.                | Advanced      |
| Combine VAE with GAN (VAE-GAN) for sharper images.                | Advanced      |
| Apply VAE to generate new drug-like molecular graphs.             | Advanced      |
| Investigate Î²-VAE for disentangled representation learning.       | Advanced      |
| Develop a hierarchical VAE for long-sequence generation.          | Advanced      |

### Diffusion Models
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Use a diffusion model to generate simple 1D noise patterns.       | Beginner      |
| Train a toy diffusion model to reconstruct noisy images.          | Beginner      |
| Implement denoising diffusion on MNIST digit images.              | Intermediate  |
| Use a pretrained diffusion model (Stable Diffusion) to generate art.| Intermediate  |
| Apply diffusion model for image super-resolution.                 | Intermediate  |
| Build a text-to-image diffusion pipeline (with CLIP guidance).     | Advanced      |
| Research improving sampling speed of diffusion models.           | Advanced      |
| Use diffusion for 3D shape or point-cloud generation.             | Advanced      |
| Combine diffusion with GAN (DiffusionGAN) for efficiency.         | Advanced      |
| Explore conditional diffusion for class-guided generation.        | Advanced      |

### Autoregressive Models (GPT, RNN-based)
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Train an RNN language model to predict the next word.             | Beginner      |
| Use GPT-2 to generate a short story given a prompt.               | Beginner      |
| Implement a character-level RNN text generator.                   | Intermediate  |
| Fine-tune an autoregressive model for code generation.            | Intermediate  |
| Explore sampling methods (top-k, nucleus) with GPT.               | Intermediate  |
| Train a Transformer-XL on long-text sequences.                    | Advanced      |
| Build a conditional text generator (e.g. style transfer).          | Advanced      |
| Research sparse autoregressive architectures (SparseGPT).        | Advanced      |
| Implement an RL loop to refine generated text quality.            | Advanced      |
| Apply autoregressive model to music (MIDI) generation.            | Advanced      |

### Normalizing Flow Models
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Implement a simple RealNVP for 2D toy data.                        | Beginner      |
| Use a normalizing flow to model a simple Gaussian mixture.        | Beginner      |
| Train MAF (Masked Autoregressive Flow) on image data.             | Intermediate  |
| Use flows for density estimation of sensor data.                  | Intermediate  |
| Combine flows with VAEs for better priors.                        | Intermediate  |
| Develop a flow-based generator for high-res images.               | Advanced      |
| Research invertible layers in deep generative models.             | Advanced      |
| Use normalizing flows for video frame prediction.                 | Advanced      |
| Implement a continuous-time flow (ODE-based) for audio.            | Advanced      |
| Explore multi-scale flows for complex high-dimensional data.       | Advanced      |

### Transformers for Generation (GPT-style)
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Use GPT to write simple dialogue between two characters.          | Beginner      |
| Generate poetry with a small transformer model.                  | Beginner      |
| Fine-tune GPT on a specialized text corpus (e.g. legal).           | Intermediate  |
| Build a headline generator using an encoder-decoder transformer.   | Intermediate  |
| Experiment with GPT output diversity via temperature tuning.      | Intermediate  |
| Develop a multi-lingual text generation model with transformer.    | Advanced      |
| Research efficient transformers (Reformer, Longformer) for long contexts.| Advanced      |
| Train a retrieval-augmented generator with external knowledge.    | Advanced      |
| Implement a transformer to generate program code.                 | Advanced      |
| Use a transformer model to generate music sequences.              | Advanced      |

### Auto-Regressive NLP Models (RNN)
| Project Idea                                                      | Difficulty    |
|-------------------------------------------------------------------|---------------|
| Train a char-level LSTM to generate text from Wikipedia.          | Beginner      |
| Use an RNN to continue writing a given paragraph.                | Beginner      |
| Build an LSTM to generate captions for images.                    | Intermediate  |
| Implement scheduled sampling to improve RNN generation.           | Intermediate  |
| Use attention in an RNN language model.                           | Intermediate  |
| Combine RNN decoder with BERT encoder for sequence generation.    | Advanced      |
| Research variational RNNs (VRNN) for diverse generation.         | Advanced      |
| Use RL to fine-tune RNN-based chatbot responses.                  | Advanced      |
| Train an RNN to generate sequential graph structures.             | Advanced      |
| Explore meta-learning for rapid adaptation of generators.        | Advanced      |

