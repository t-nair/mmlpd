# XAI Hub
## Full Project Database
* [Jump to tables by topic](#tables-by-topic)

| Topic                                     | Project Idea                                                               | Difficulty    |
|-------------------------------------------|----------------------------------------------------------------------------|---------------|
| LIME (Local Interpretable Model-agnostic Explanations) | Explain a black-box model’s prediction for a single instance.             | Beginner      |
| LIME (Local Interpretable Model-agnostic Explanations) | Visualize feature contributions of a decision tree with LIME.          | Beginner      |
| LIME (Local Interpretable Model-agnostic Explanations) | Compare LIME explanations for two different models on the same input. | Intermediate  |
| LIME (Local Interpretable Model-agnostic Explanations) | Use LIME to interpret a text classifier’s prediction.                | Intermediate  |
| LIME (Local Interpretable Model-agnostic Explanations) | Evaluate LIME’s stability across similar data points.                | Intermediate  |
| LIME (Local Interpretable Model-agnostic Explanations) | Extend LIME for image models (superpixel explanations).             | Advanced      |
| LIME (Local Interpretable Model-agnostic Explanations) | Apply LIME to time-series forecasting models.                        | Advanced      |
| LIME (Local Interpretable Model-agnostic Explanations) | Research LIME limitations for high-dimensional datasets.              | Advanced      |
| LIME (Local Interpretable Model-agnostic Explanations) | Integrate LIME explanations into a user interface.                  | Advanced      |
| LIME (Local Interpretable Model-agnostic Explanations) | Use LIME to explain an ensemble of models’ outputs.                 | Advanced      |
| SHAP (SHapley Additive exPlanations)      | Compute SHAP values for a random forest model.                            | Beginner      |
| SHAP (SHapley Additive exPlanations)      | Use SHAP summary plot on a classification dataset.                        | Beginner      |
| SHAP (SHapley Additive exPlanations)      | Compare SHAP vs LIME explanations on the same data.                      | Intermediate  |
| SHAP (SHapley Additive exPlanations)      | Explain predictions of an XGBoost model with SHAP.                        | Intermediate  |
| SHAP (SHapley Additive exPlanations)      | Use SHAP for feature selection analysis.                                  | Intermediate  |
| SHAP (SHapley Additive exPlanations)      | Implement TreeSHAP for fast computation on tree models.                   | Advanced      |
| SHAP (SHapley Additive exPlanations)      | Research DeepSHAP for neural network interpretation.                      | Advanced      |
| SHAP (SHapley Additive exPlanations)      | Apply SHAP to explain recommendations in a recsys.                        | Advanced      |
| SHAP (SHapley Additive exPlanations)      | Combine SHAP with dimensionality reduction for insights.                   | Advanced      |
| SHAP (SHapley Additive exPlanations)      | Use SHAP to identify bias in a model’s decisions.                       | Advanced      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Generate Grad-CAM heatmaps for a CNN image classifier.                | Beginner      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Visualize important image regions for object classification.          | Beginner      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Implement Grad-CAM for multiple layers of a CNN.                      | Intermediate  |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Compare Grad-CAM and Guided Backprop visualizations.                | Intermediate  |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Use Grad-CAM for analysis of misclassified images.                  | Intermediate  |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Adapt Grad-CAM to a ResNet or DenseNet model.                        | Advanced      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Apply Grad-CAM to explain medical image diagnoses.                    | Advanced      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Research Grad-CAM++ for finer localization.                         | Advanced      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Combine Grad-CAM with LIME for multimodal images.                   | Advanced      |
| Grad-CAM (Gradient-weighted Class Activation Mapping) | Use Grad-CAM to explain video frame predictions.                    | Advanced      |
| Integrated Gradients                    | Compute integrated gradients for a small neural network.                  | Beginner      |
| Integrated Gradients                    | Visualize integrated gradients attributions on image pixels.            | Beginner      |
| Integrated Gradients                    | Use integrated gradients to explain text model predictions.             | Intermediate  |
| Integrated Gradients                    | Compare integrated gradients and saliency maps.                         | Intermediate  |
| Integrated Gradients                    | Implement integrated gradients for a TensorFlow model.                  | Intermediate  |
| Integrated Gradients                    | Research SmoothGrad to reduce noise in attributions.                    | Advanced      |
| Integrated Gradients                    | Use integrated gradients to analyze model bias.                       | Advanced      |
| Integrated Gradients                    | Combine integrated gradients with layer-wise relevance propagation.     | Advanced      |
| Integrated Gradients                    | Implement integrated gradients for an RL policy network.                | Advanced      |
| Integrated Gradients                    | Evaluate fairness by integrated gradients for different user groups.    | Advanced      |
| Counterfactual Explanations             | Find minimal feature change to flip a classifier’s decision.             | Beginner      |
| Counterfactual Explanations             | Generate a counterfactual for a loan approval model.                   | Beginner      |
| Counterfactual Explanations             | Use DiCE library to create counterfactual examples.                    | Intermediate  |
| Counterfactual Explanations             | Compare counterfactual vs LIME explanations for one case.              | Intermediate  |
| Counterfactual Explanations             | Use counterfactuals to highlight bias in model predictions.            | Intermediate  |
| Counterfactual Explanations             | Create actionable counterfactuals for image classification changes.     | Advanced      |
| Counterfactual Explanations             | Research generating counterfactuals with generative models.             | Advanced      |
| Counterfactual Explanations             | Implement counterfactuals for time-series anomaly cases.                | Advanced      |
| Counterfactual Explanations             | Evaluate robustness of counterfactual explanations.                     | Advanced      |
| Counterfactual Explanations             | Apply counterfactuals to validate feature importance claims.            | Advanced      |
| Model Distillation (Surrogates)         | Train a decision tree to mimic a complex model’s predictions.          | Beginner      |
| Model Distillation (Surrogates)         | Use a shallow neural net as a surrogate for explanation.              | Beginner      |
| Model Distillation (Surrogates)         | Distill a deep model into a smaller one for deployment.               | Intermediate  |
| Model Distillation (Surrogates)         | Train a rule list model to approximate a black-box.                   | Intermediate  |
| Model Distillation (Surrogates)         | Compare surrogate fidelity using accuracy metrics.                     | Intermediate  |
| Model Distillation (Surrogates)         | Research explainable boosted trees (e.g. EBMs).                         | Advanced      |
| Model Distillation (Surrogates)         | Develop a symbolic regression model as an explanatory surrogate.      | Advanced      |
| Model Distillation (Surrogates)         | Use knowledge distillation to compress ensembles.                      | Advanced      |
| Model Distillation (Surrogates)         | Explore Bayesian surrogate models for uncertainty.                    | Advanced      |
| Model Distillation (Surrogates)         | Implement surrogate evaluation for different input domains.             | Advanced      |
| Feature Importance (Permutation, PDP)   | Compute permutation importance on a trained model.                      | Beginner      |
| Feature Importance (Permutation, PDP)   | Plot partial dependence for a top feature.                            | Beginner      |
| Feature Importance (Permutation, PDP)   | Use SHAP (or PDP) to find global feature importance.                  | Intermediate  |
| Feature Importance (Permutation, PDP)   | Compare feature importance across multiple models.                    | Intermediate  |
| Feature Importance (Permutation, PDP)   | Analyze importance for categorical vs numeric features.               | Intermediate  |
| Feature Importance (Permutation, PDP)   | Research correlated features effect on importance metrics.            | Advanced      |
| Feature Importance (Permutation, PDP)   | Implement ICE (individual conditional expectation) plots.               | Advanced      |
| Feature Importance (Permutation, PDP)   | Use PDPs for non-linear feature effect analysis.                      | Advanced      |
| Feature Importance (Permutation, PDP)   | Combine PDP with SHAP for robust insights.                            | Advanced      |
| Feature Importance (Permutation, PDP)   | Validate feature importance with ablation studies.                    | Advanced      |
| Saliency Maps (Raw Gradients)           | Generate a saliency map for a CNN output.                             | Beginner      |
| Saliency Maps (Raw Gradients)           | Highlight pixels affecting a classifier’s decision.                   | Beginner      |
| Saliency Maps (Raw Gradients)           | Compare saliency vs Grad-CAM explanations.                            | Intermediate  |
| Saliency Maps (Raw Gradients)           | Apply smoothing to reduce saliency map noise.                         | Intermediate  |
| Saliency Maps (Raw Gradients)           | Use saliency maps for text (attention heatmap).                       | Intermediate  |
| Saliency Maps (Raw Gradients)           | Research Guided Backpropagation vs vanilla gradients.                 | Advanced      |
| Saliency Maps (Raw Gradients)           | Implement SmoothGrad to improve saliency.                             | Advanced      |
| Saliency Maps (Raw Gradients)           | Evaluate saliency on adversarial examples.                          | Advanced      |
| Saliency Maps (Raw Gradients)           | Use saliency in model debugging to find biases.                       | Advanced      |
| Saliency Maps (Raw Gradients)           | Apply saliency to sequence models (RNN/LSTM) inputs.                  | Advanced      |

## Tables by Topic
### LIME (Local Interpretable Model-agnostic Explanations)
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Explain a black-box model’s prediction for a single instance.             | Beginner      |
| Visualize feature contributions of a decision tree with LIME.          | Beginner      |
| Compare LIME explanations for two different models on the same input. | Intermediate  |
| Use LIME to interpret a text classifier’s prediction.                | Intermediate  |
| Evaluate LIME’s stability across similar data points.                | Intermediate  |
| Extend LIME for image models (superpixel explanations).             | Advanced      |
| Apply LIME to time-series forecasting models.                        | Advanced      |
| Research LIME limitations for high-dimensional datasets.              | Advanced      |
| Integrate LIME explanations into a user interface.                  | Advanced      |
| Use LIME to explain an ensemble of models’ outputs.                 | Advanced      |

### SHAP (SHapley Additive exPlanations)
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Compute SHAP values for a random forest model.                            | Beginner      |
| Use SHAP summary plot on a classification dataset.                        | Beginner      |
| Compare SHAP vs LIME explanations on the same data.                      | Intermediate  |
| Explain predictions of an XGBoost model with SHAP.                        | Intermediate  |
| Use SHAP for feature selection analysis.                                  | Intermediate  |
| Implement TreeSHAP for fast computation on tree models.                   | Advanced      |
| Research DeepSHAP for neural network interpretation.                      | Advanced      |
| Apply SHAP to explain recommendations in a recsys.                        | Advanced      |
| Combine SHAP with dimensionality reduction for insights.                   | Advanced      |
| Use SHAP to identify bias in a model’s decisions.                       | Advanced      |

### Grad-CAM (Gradient-weighted Class Activation Mapping)
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Generate Grad-CAM heatmaps for a CNN image classifier.                | Beginner      |
| Visualize important image regions for object classification.          | Beginner      |
| Implement Grad-CAM for multiple layers of a CNN.                      | Intermediate  |
| Compare Grad-CAM and Guided Backprop visualizations.                | Intermediate  |
| Use Grad-CAM for analysis of misclassified images.                  | Intermediate  |
| Adapt Grad-CAM to a ResNet or DenseNet model.                        | Advanced      |
| Apply Grad-CAM to explain medical image diagnoses.                    | Advanced      |
| Research Grad-CAM++ for finer localization.                         | Advanced      |
| Combine Grad-CAM with LIME for multimodal images.                   | Advanced      |
| Use Grad-CAM to explain video frame predictions.                    | Advanced      |

### Integrated Gradients
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Compute integrated gradients for a small neural network.                  | Beginner      |
| Visualize integrated gradients attributions on image pixels.            | Beginner      |
| Use integrated gradients to explain text model predictions.             | Intermediate  |
| Compare integrated gradients and saliency maps.                         | Intermediate  |
| Implement integrated gradients for a TensorFlow model.                  | Intermediate  |
| Research SmoothGrad to reduce noise in attributions.                    | Advanced      |
| Use integrated gradients to analyze model bias.                       | Advanced      |
| Combine integrated gradients with layer-wise relevance propagation.     | Advanced      |
| Implement integrated gradients for an RL policy network.                | Advanced      |
| Evaluate fairness by integrated gradients for different user groups.    | Advanced      |

### Counterfactual Explanations
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Find minimal feature change to flip a classifier’s decision.             | Beginner      |
| Generate a counterfactual for a loan approval model.                   | Beginner      |
| Use DiCE library to create counterfactual examples.                    | Intermediate  |
| Compare counterfactual vs LIME explanations for one case.              | Intermediate  |
| Use counterfactuals to highlight bias in model predictions.            | Intermediate  |
| Create actionable counterfactuals for image classification changes.     | Advanced      |
| Research generating counterfactuals with generative models.             | Advanced      |
| Implement counterfactuals for time-series anomaly cases.                | Advanced      |
| Evaluate robustness of counterfactual explanations.                     | Advanced      |
| Apply counterfactuals to validate feature importance claims.            | Advanced      |

### Model Distillation (Surrogates)
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Train a decision tree to mimic a complex model’s predictions.          | Beginner      |
| Use a shallow neural net as a surrogate for explanation.              | Beginner      |
| Distill a deep model into a smaller one for deployment.               | Intermediate  |
| Train a rule list model to approximate a black-box.                   | Intermediate  |
| Compare surrogate fidelity using accuracy metrics.                     | Intermediate  |
| Research explainable boosted trees (e.g. EBMs).                         | Advanced      |
| Develop a symbolic regression model as an explanatory surrogate.      | Advanced      |
| Use knowledge distillation to compress ensembles.                      | Advanced      |
| Explore Bayesian surrogate models for uncertainty.                    | Advanced      |
| Implement surrogate evaluation for different input domains.             | Advanced      |

### Feature Importance (Permutation, PDP)
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Compute permutation importance on a trained model.                      | Beginner      |
| Plot partial dependence for a top feature.                            | Beginner      |
| Use SHAP (or PDP) to find global feature importance.                  | Intermediate  |
| Compare feature importance across multiple models.                    | Intermediate  |
| Analyze importance for categorical vs numeric features.               | Intermediate  |
| Research correlated features effect on importance metrics.            | Advanced      |
| Implement ICE (individual conditional expectation) plots.               | Advanced      |
| Use PDPs for non-linear feature effect analysis.                      | Advanced      |
| Combine PDP with SHAP for robust insights.                            | Advanced      |
| Validate feature importance with ablation studies.                    | Advanced      |

### Saliency Maps (Raw Gradients)
| Project Idea                                                               | Difficulty    |
|----------------------------------------------------------------------------|---------------|
| Generate a saliency map for a CNN output.                             | Beginner      |
| Highlight pixels affecting a classifier’s decision.                   | Beginner      |
| Compare saliency vs Grad-CAM explanations.                            | Intermediate  |
| Apply smoothing to reduce saliency map noise.                         | Intermediate  |
| Use saliency maps for text (attention heatmap).                       | Intermediate  |
| Research Guided Backpropagation vs vanilla gradients.                 | Advanced      |
| Implement SmoothGrad to improve saliency.                             | Advanced      |
| Evaluate saliency on adversarial examples.                          | Advanced      |
| Use saliency in model debugging to find biases.                       | Advanced      |
| Apply saliency to sequence models (RNN/LSTM) inputs.                  | Advanced      |

[![follow banner](https://github.com/user-attachments/assets/d1b3ca08-dfea-403d-b4f1-613cedb83e11)](https://linktr.ee/mlinguist)
